{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44d7fc51",
   "metadata": {},
   "source": [
    "# MNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56798c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Set the GPUs to use\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import DataParallel\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "from src.mnist.datasets import get_mnist_dataloaders, convert_flattened_to_image, get_merged_labels\n",
    "from src.mnist.models import CVAE, InvariantAutoEncoder, InvariantVariationalAutoEncoder, ProxyRep2InvarRep, ProxyRep2Label\n",
    "from src.mnist.losses import CVAE_Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25331919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1e-3 at BS=50 works OK, 4e-4 is even better\n",
    "# 1e-4 at BS=50 almost overfits\n",
    "# 4e-5 at BS=500 works like 4e-4 at BS=50\n",
    "\n",
    "BATCH_SIZE = 500\n",
    "BETA = 4e-5  # Scaled by batch size for stability\n",
    "REDUCTION = 'mean'\n",
    "EPOCHS = 50\n",
    "LR = 5e-4  # Learning rate\n",
    "CVAE_PATH = \"../checkpoints/mnist/digit/cvae.pth\"\n",
    "\n",
    "mnist_train, mnist_val, mnist_test = get_mnist_dataloaders(\"../data\", one_hot=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "cvae = CVAE(28 * 28, 128, 64)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs for training.\")\n",
    "    cvae = DataParallel(cvae)\n",
    "cvae = cvae.to(device)\n",
    "\n",
    "if os.path.exists(CVAE_PATH):\n",
    "    print(\"Loading pre-trained CVAE model...\")\n",
    "    cvae.load_state_dict(torch.load(CVAE_PATH, map_location=device))\n",
    "else:\n",
    "    print(\"No pre-trained model found. Starting from scratch.\")\n",
    "    optimizer = optim.Adam(cvae.parameters(), lr=LR)\n",
    "    loss_fn = CVAE_Loss(beta=BETA, reduction=REDUCTION)\n",
    "\n",
    "    losses_train = []\n",
    "    losses_val = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "        cvae.train()\n",
    "        for i, (x, y) in enumerate(tqdm(mnist_train)):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon_x, mu, logvar = cvae(x, y)\n",
    "            loss = loss_fn(recon_x, x, mu, logvar)\n",
    "            loss.backward()\n",
    "            losses_train.append(loss.item())\n",
    "            optimizer.step()\n",
    "            # print(f\"{i + 1:>3}/{len(mnist_train)}: {loss.item():.4f}\", end=\"\\r\")\n",
    "        with torch.no_grad():\n",
    "            cvae.eval()\n",
    "            total_val_loss = 0\n",
    "            for x, y in mnist_val:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                recon_x, mu, logvar = cvae(x, y)\n",
    "                val_loss = loss_fn(recon_x, x, mu, logvar)\n",
    "                total_val_loss += val_loss.item()\n",
    "            avg_val_loss = total_val_loss / len(mnist_val)\n",
    "            losses_val.append(avg_val_loss)\n",
    "            print(f\"\\nEpoch {epoch + 1} Validation Loss: {avg_val_loss:.4f}\")\n",
    "    torch.save(cvae.state_dict(), CVAE_PATH)\n",
    "\n",
    "\n",
    "    nb_minibatches = len(mnist_train)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses_train, label='Training Loss', color='blue')\n",
    "    plt.plot(range(nb_minibatches, nb_minibatches * EPOCHS + 1, nb_minibatches), losses_val, label='Validation Loss', color='orange')\n",
    "    plt.xlabel('Batch Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Losses')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ae22ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_SAMPLES = 8\n",
    "NB_subplots = 8\n",
    "nb_figures = NB_SAMPLES // NB_subplots\n",
    "\n",
    "for x, y in mnist_test:\n",
    "    # print(x.shape, y.shape)\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    break\n",
    "\n",
    "cvae.encoder(x)\n",
    "y_shuffled = y[torch.randperm(y.size(0))]\n",
    "x_shuffled_recon, mu, logvar = cvae(x, y_shuffled)\n",
    "x_recon = cvae(x, y)[0]\n",
    "\n",
    "for f in range(nb_figures):\n",
    "    fig, axs = plt.subplots(3, NB_subplots, figsize=(NB_subplots*2, 6))\n",
    "    for idx in range(min(NB_subplots, NB_SAMPLES - f * NB_subplots)):\n",
    "        axs[0, idx].imshow(x[f * NB_subplots + idx].cpu().reshape(28, 28), cmap=\"gray\")\n",
    "        axs[0, idx].set_title(f\"{y[f * NB_subplots + idx].argmax()}\")\n",
    "        axs[0, idx].set_xticks([])\n",
    "        axs[0, idx].set_yticks([])\n",
    "\n",
    "        axs[1, idx].imshow(x_recon[f * NB_subplots + idx].detach().cpu().reshape(28, 28), cmap=\"gray\")\n",
    "        axs[1, idx].set_title(f\"$S$ = {y[f * NB_subplots + idx].argmax()}\")\n",
    "        axs[1, idx].set_xticks([])\n",
    "        axs[1, idx].set_yticks([])\n",
    "\n",
    "        axs[2, idx].imshow(x_shuffled_recon[f * NB_subplots + idx].detach().cpu().reshape(28, 28), cmap=\"gray\")\n",
    "        axs[2, idx].set_title(f\"$S$ = {y_shuffled[f * NB_subplots + idx].argmax()}\")\n",
    "        axs[2, idx].set_xticks([])\n",
    "        axs[2, idx].set_yticks([])\n",
    "    axs[0, 0].set_ylabel(\"Original\")\n",
    "    axs[1, 0].set_ylabel(\"Reconstructed\")\n",
    "    axs[2, 0].set_ylabel(\"Shuffled\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\" \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bea5190",
   "metadata": {},
   "source": [
    "## Inv. AE z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1e74c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z2_DIM = 4  # Dimension of the latent space for invariant VAE\n",
    "INAE_PATH = \"../checkpoints/mnist/digit/invariant_ae.pth\"\n",
    "# make cvae not trainable\n",
    "for param in cvae.parameters():\n",
    "    param.requires_grad = False\n",
    "# make invariant vae trainable\n",
    "inae = InvariantAutoEncoder(28 * 28, 128, Z2_DIM, cvae=cvae)\n",
    "inae = inae.to(device)\n",
    "\n",
    "if os.path.exists(INAE_PATH):\n",
    "    print(\"Loading pre-trained Invariant AE model...\")\n",
    "    inae.load_state_dict(torch.load(INAE_PATH, map_location=device))\n",
    "else:\n",
    "    print(\"No pre-trained model found. Starting from scratch.\")\n",
    "\n",
    "    optimizer = optim.Adam(inae.parameters(), lr=1e-3)\n",
    "    loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "    losses_train = []\n",
    "    losses_val = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "        inae.train()\n",
    "        for i, (x, y) in enumerate(tqdm(mnist_train)):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon_x = inae(x)\n",
    "            loss = loss_fn(recon_x, x)\n",
    "            loss.backward()\n",
    "            losses_train.append(loss.item())\n",
    "            optimizer.step()\n",
    "            # print(f\"{i + 1:>3}/{len(mnist_train)}: {loss.item():.4f}\", end=\"\\r\")\n",
    "        with torch.no_grad():\n",
    "            inae.eval()\n",
    "            total_val_loss = 0\n",
    "            for x, y in mnist_val:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                recon_x = inae(x)\n",
    "                val_loss = loss_fn(recon_x, x)\n",
    "                total_val_loss += val_loss.item()\n",
    "            avg_val_loss = total_val_loss / len(mnist_val)\n",
    "            losses_val.append(avg_val_loss)\n",
    "            print(f\"\\nEpoch {epoch + 1} Validation Loss: {avg_val_loss:.4f}\")\n",
    "    torch.save(inae.state_dict(), INAE_PATH)\n",
    "\n",
    "    nb_minibatches = len(mnist_train)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses_train, label='Training Loss', color='blue')\n",
    "    plt.plot(range(nb_minibatches, nb_minibatches * EPOCHS + 1, nb_minibatches),\n",
    "             losses_val, label='Validation Loss', color='orange')\n",
    "    plt.xlabel('Batch Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Losses')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70840a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_SAMPLES = 32\n",
    "NB_subplots = 8\n",
    "nb_figures = NB_SAMPLES // NB_subplots\n",
    "\n",
    "for x, y in mnist_test:\n",
    "    # print(x.shape, y.shape)\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    break\n",
    "\n",
    "x_recon_cvae = cvae(x, y)[0]\n",
    "x_recon_inae = inae(x)\n",
    "\n",
    "for f in range(nb_figures):\n",
    "    fig, axs = plt.subplots(3, NB_subplots, figsize=(NB_subplots*2, 6))\n",
    "    for idx in range(min(NB_subplots, NB_SAMPLES - f * NB_subplots)):\n",
    "        axs[0, idx].imshow(x[f * NB_subplots + idx].cpu().reshape(28, 28), cmap=\"gray\")\n",
    "        axs[0, idx].set_title(f\"{y[f * NB_subplots + idx].argmax()}\")\n",
    "        axs[0, idx].set_xticks([])\n",
    "        axs[0, idx].set_yticks([])\n",
    "\n",
    "        axs[1, idx].imshow(x_recon_cvae[f * NB_subplots + idx].detach().cpu().reshape(28, 28), cmap=\"gray\")\n",
    "        axs[1, idx].set_title(\" \")\n",
    "        axs[1, idx].set_xticks([])\n",
    "        axs[1, idx].set_yticks([])\n",
    "\n",
    "        axs[2, idx].imshow(x_recon_inae[f * NB_subplots + idx].detach().cpu().reshape(28, 28), cmap=\"gray\")\n",
    "        axs[2, idx].set_title(\" \")\n",
    "        axs[2, idx].set_xticks([])\n",
    "        axs[2, idx].set_yticks([])\n",
    "    axs[0, 0].set_ylabel(\"Original\")\n",
    "    axs[1, 0].set_ylabel(\"CVAE Recon.\")\n",
    "    axs[2, 0].set_ylabel(\"InvAE Recon.\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd530fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT = 40\n",
    "x = []\n",
    "y = []\n",
    "for x_tmp, y_tmp in mnist_test:\n",
    "    x.append(x_tmp)\n",
    "    y.append(y_tmp)\n",
    "x = torch.cat(x).to(device)\n",
    "y = torch.cat(y).to(device)\n",
    "label = y.argmax(axis=1).detach().cpu()\n",
    "x_recon_inv_vae = inae(x)\n",
    "z = inae.encoder(x)\n",
    "z = z.detach().cpu()\n",
    "z_centers = []\n",
    "for i in range(10):\n",
    "    center = z[label == i].mean(axis=0)\n",
    "    z_centers.append(center)\n",
    "z_centers = torch.stack(z_centers)\n",
    "\n",
    "fig, axes = plt.subplots(Z2_DIM - 1, Z2_DIM - 1, figsize=(5 * (Z2_DIM - 1), 5 * (Z2_DIM - 1)), tight_layout=True)\n",
    "for i in range(Z2_DIM - 1):\n",
    "    for j in range(1, Z2_DIM):\n",
    "        if i < j:\n",
    "            im = axes[i, j-1].scatter(z_centers[:, i], z_centers[:, j],\n",
    "                                    c=range(10), cmap=\"tab10\", vmin=-.5, vmax=9.5)\n",
    "            axes[i, j-1].scatter(z[:, i], z[:, j],\n",
    "                            c=label, cmap=\"tab10\", alpha=0.1)\n",
    "            axes[i, j-1].set_aspect('equal', adjustable='box')\n",
    "            axes[i, j-1].set_xlim(-LIMIT, LIMIT)\n",
    "            axes[i, j-1].set_ylim(-LIMIT, LIMIT)\n",
    "            for d in range(10):\n",
    "                axes[i, j-1].text(z_centers[d][i], z_centers[d][j], str(d), fontsize=15, ha='center', va='center')\n",
    "        else:\n",
    "            axes[i, j-1].axis('off')\n",
    "\n",
    "for i in range(Z2_DIM - 1):\n",
    "    for j in range(Z2_DIM - 1):\n",
    "        if i == j :\n",
    "            axes[i, j].set_ylabel(f\"$z_2$[{i}]\", fontsize=15)\n",
    "            axes[i, j].set_xlabel(f\"$z_2$[{j + 1}]\", fontsize=15)\n",
    "        elif i > j:\n",
    "            axes[i, j].axis('off')\n",
    "        else:\n",
    "            axes[i, j].set_xticks([])\n",
    "            axes[i, j].set_yticks([])\n",
    "\n",
    "plt.suptitle(\"Latent Space of Invariant AE\", fontsize=20)\n",
    "cbar = plt.colorbar(im, ax=axes, orientation='horizontal',\n",
    "                    fraction=0.02, pad=0.0)\n",
    "cbar.set_label('Digit Label', fontsize=15)\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "cbar.set_ticks(range(10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275db2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# import numpy as np\n",
    "# pca = PCA(n_components=2)\n",
    "\n",
    "# z = invae.encoder(x)\n",
    "# z = z.detach().cpu()\n",
    "# z = pca.fit_transform(z)\n",
    "# z_centers = []\n",
    "# for i in range(10):\n",
    "#     center = z[label == i].mean(axis=0)\n",
    "#     z_centers.append(center)\n",
    "# z_centers = np.stack(z_centers)\n",
    "\n",
    "# im = plt.scatter(z_centers[:, 0], z_centers[:, 1], c=range(10), cmap=\"tab10\")\n",
    "# plt.scatter(z[:, 0], z[:, 1], c=label, cmap=\"tab10\", alpha=0.1)\n",
    "# plt.gca().set_aspect('equal')\n",
    "# plt.colorbar(im)\n",
    "# for i in range(10):\n",
    "#     plt.text(z_centers[i][0], z_centers[i][1], str(i), fontsize=12, ha='center', va='center')\n",
    "\n",
    "# # plt.title(\"$z_1$\")\n",
    "# plt.xlabel(\"$z_1$[0]\")\n",
    "# plt.ylabel(\"$z_1$[1]\")\n",
    "# # plt.xlim(-LIMIT, LIMIT)\n",
    "# # plt.ylim(-LIMIT, LIMIT)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e30e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROXY2INVAR_PATH = \"../checkpoints/mnist/digit/aeproxy2invar.pth\"\n",
    "\n",
    "for param in cvae.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in inae.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "proxy2invar = ProxyRep2InvarRep(autoencoder=inae, reparameterize=False)\n",
    "proxy2invar = proxy2invar.to(device)\n",
    "\n",
    "if os.path.exists(PROXY2INVAR_PATH):\n",
    "    print(\"Loading pre-trained Proxy2Invar model...\")\n",
    "    proxy2invar.load_state_dict(torch.load(PROXY2INVAR_PATH, map_location=device))\n",
    "else:\n",
    "    print(\"No pre-trained model found. Starting from scratch.\")\n",
    "    optimizer = optim.Adam(proxy2invar.parameters(), lr=1e-3)\n",
    "    loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "    losses_train = []\n",
    "    losses_val = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "        proxy2invar.train()\n",
    "        for i, (x, y) in enumerate(tqdm(mnist_train)):\n",
    "            x = x.to(device)\n",
    "            \n",
    "            # Get real invariant representation from CVAE\n",
    "            with torch.no_grad():\n",
    "                z_invar = inae.cvae.encoder(x)\n",
    "                mu = z_invar[:, :inae.cvae.latent_dim]\n",
    "                logvar = z_invar[:, inae.cvae.latent_dim:]\n",
    "                z_invar = inae.cvae.reparameterize(mu, logvar)\n",
    "            \n",
    "            z_invar_pred = proxy2invar(x)\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(z_invar_pred, z_invar)\n",
    "            loss.backward()\n",
    "            losses_train.append(loss.item())\n",
    "            optimizer.step()\n",
    "\n",
    "        proxy2invar.eval()\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for x, y in mnist_val:\n",
    "                x = x.to(device)\n",
    "                z_invar = inae.cvae.encoder(x)\n",
    "                mu = z_invar[:, :inae.cvae.latent_dim]\n",
    "                logvar = z_invar[:, inae.cvae.latent_dim:]\n",
    "                z_invar = inae.cvae.reparameterize(mu, logvar)\n",
    "\n",
    "                z_invar_pred = proxy2invar(x)\n",
    "                val_loss = loss_fn(z_invar_pred, z_invar)\n",
    "                total_val_loss += val_loss.item()\n",
    "            avg_val_loss = total_val_loss / len(mnist_val)\n",
    "            losses_val.append(avg_val_loss)\n",
    "            print(f\"\\nEpoch {epoch + 1} Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    torch.save(proxy2invar.state_dict(), PROXY2INVAR_PATH)\n",
    "\n",
    "    nb_minibatches = len(mnist_train)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses_train, label='Training Loss', color='blue')\n",
    "    plt.plot(range(nb_minibatches, nb_minibatches * EPOCHS + 1, nb_minibatches),\n",
    "                losses_val, label='Validation Loss', color='orange')\n",
    "    plt.xlabel('Batch Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('AE Proxy to Invariant Representation MSE')\n",
    "    plt.legend()\n",
    "    plt.xscale('log')\n",
    "    plt.ylim(0.94, 1.1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6711ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROXY2LAB_PATH = \"../checkpoints/mnist/digit/aeproxy2lab.pth\"\n",
    "\n",
    "proxy2lab = ProxyRep2Label(autoencoder=inae, reparameterize=False, nb_labels=10)\n",
    "proxy2lab = proxy2lab.to(device)\n",
    "\n",
    "if os.path.exists(PROXY2LAB_PATH):\n",
    "    print(\"Loading pre-trained Proxy2Label model...\")\n",
    "    proxy2lab.load_state_dict(torch.load(PROXY2LAB_PATH, map_location=device))\n",
    "else:\n",
    "    print(\"No pre-trained model found. Starting from scratch.\")\n",
    "    optimizer = optim.Adam(proxy2lab.parameters(), lr=1e-3)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "    losses_train = []\n",
    "    losses_val = []\n",
    "    accuracies_val = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "        proxy2lab.train()\n",
    "        for i, (x, y) in enumerate(tqdm(mnist_train)):\n",
    "            x = x.to(device)\n",
    "            y = y.float().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = proxy2lab(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            loss.backward()\n",
    "            losses_train.append(loss.item())\n",
    "            optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            proxy2lab.eval()\n",
    "            total_val_loss = 0\n",
    "            total_val_accu = 0\n",
    "\n",
    "            for x, y in mnist_val:\n",
    "                x = x.to(device)\n",
    "                y = y.float().to(device)\n",
    "                y_pred = proxy2lab(x)\n",
    "                val_loss = loss_fn(y_pred, y)\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "                lab_pred = y_pred.argmax(axis=1)\n",
    "                lab_true = y.argmax(axis=1)\n",
    "                acc = (lab_pred == lab_true).float().mean().item()\n",
    "                total_val_accu += acc\n",
    "\n",
    "            avg_val_loss = total_val_loss / len(mnist_val)\n",
    "            avg_val_accu = total_val_accu / len(mnist_val)\n",
    "            accuracies_val.append(avg_val_accu)\n",
    "            print(f\"\\nEpoch {epoch + 1} Validation Loss: {avg_val_loss:.4f}, Accuracy: {avg_val_accu:.4f}\")\n",
    "            losses_val.append(avg_val_loss)\n",
    "            print(f\"\\nEpoch {epoch + 1} Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "    torch.save(proxy2lab.state_dict(), PROXY2LAB_PATH)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n",
    "    axes[0].plot(losses_train, label='Training Loss', color='blue')\n",
    "    axes[0].plot(range(nb_minibatches, nb_minibatches * EPOCHS + 1, nb_minibatches),\n",
    "                losses_val, label='Validation Loss', color='orange')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('AE Proxy to Label Cross Entropy')\n",
    "    axes[0].legend()\n",
    "    axes[0].set_xscale('log')\n",
    "    axes[0].set_xticks([])\n",
    "    xlim = axes[0].get_xlim()\n",
    "\n",
    "    axes[1].plot(range(nb_minibatches, nb_minibatches * EPOCHS + 1, nb_minibatches),\n",
    "                accuracies_val, label='Validation Accuracy', color='green')\n",
    "    axes[1].set_xlabel('Batch Iterations')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('AE Proxy to Label Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].set_xscale('log')\n",
    "    axes[1].set_xlim(xlim)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b5146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy2lab.eval()\n",
    "\n",
    "lab_true_all = []\n",
    "lab_pred_all = []\n",
    "\n",
    "for x, y in mnist_test:\n",
    "    x = x.to(device)\n",
    "    y = y.float().to(device)\n",
    "    lab_true = y.argmax(axis=1)\n",
    "    lab_true_all.append(lab_true)\n",
    "\n",
    "    y_pred = proxy2lab(x)\n",
    "    lab_pred = y_pred.argmax(axis=1)\n",
    "    lab_pred_all.append(lab_pred)\n",
    "lab_true_all = torch.cat(lab_true_all).detach().cpu()\n",
    "lab_pred_all = torch.cat(lab_pred_all).detach().cpu()\n",
    "confusion_matrix = torch.zeros(10, 10, dtype=torch.int64)\n",
    "for true, pred in zip(lab_true_all, lab_pred_all):\n",
    "    confusion_matrix[true, pred] += 1\n",
    "accuracy = (lab_true_all == lab_pred_all).float().mean().item()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(confusion_matrix, cmap='Blues', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title(f\"Confusion Matrix of AE Proxy to Label (acc.: {accuracy:.3f})\")\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.xticks(ticks=range(10), labels=range(10))\n",
    "plt.yticks(ticks=range(10), labels=range(10))\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797ab512",
   "metadata": {},
   "source": [
    "## Inv. VAE z2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b90f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z2_DIM = 4  # Dimension of the latent space for invariant VAE\n",
    "INVAE_PATH = \"../checkpoints/mnist/digit/invariant_vae.pth\"\n",
    "# make cvae not trainable\n",
    "for param in cvae.parameters():\n",
    "    param.requires_grad = False\n",
    "# make invariant vae trainable\n",
    "invae = InvariantVariationalAutoEncoder(28 * 28, 128, Z2_DIM, cvae=cvae)\n",
    "invae = invae.to(device)\n",
    "\n",
    "if os.path.exists(INVAE_PATH):\n",
    "    print(\"Loading pre-trained Invariant AE model...\")\n",
    "    invae.load_state_dict(torch.load(INVAE_PATH, map_location=device))\n",
    "else:\n",
    "    print(\"No pre-trained model found. Starting from scratch.\")\n",
    "\n",
    "    optimizer = optim.Adam(invae.parameters(), lr=1e-3)\n",
    "    loss_fn = CVAE_Loss(beta=BETA, reduction=REDUCTION)\n",
    "\n",
    "    losses_train = []\n",
    "    losses_val = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "        invae.train()\n",
    "        for i, (x, y) in enumerate(tqdm(mnist_train)):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon_x, mu, logvar = invae(x)\n",
    "            loss = loss_fn(recon_x, x, mu, logvar)\n",
    "            loss.backward()\n",
    "            losses_train.append(loss.item())\n",
    "            optimizer.step()\n",
    "            # print(f\"{i + 1:>3}/{len(mnist_train)}: {loss.item():.4f}\", end=\"\\r\")\n",
    "        with torch.no_grad():\n",
    "            invae.eval()\n",
    "            total_val_loss = 0\n",
    "            for x, y in mnist_val:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                recon_x, mu, logvar = invae(x)\n",
    "                val_loss = loss_fn(recon_x, x, mu, logvar)\n",
    "                total_val_loss += val_loss.item()\n",
    "            avg_val_loss = total_val_loss / len(mnist_val)\n",
    "            losses_val.append(avg_val_loss)\n",
    "            print(f\"\\nEpoch {epoch + 1} Validation Loss: {avg_val_loss:.4f}\")\n",
    "    torch.save(invae.state_dict(), INVAE_PATH)\n",
    "\n",
    "    nb_minibatches = len(mnist_train)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses_train, label='Training Loss', color='blue')\n",
    "    plt.plot(range(nb_minibatches, nb_minibatches * EPOCHS + 1, nb_minibatches),\n",
    "             losses_val, label='Validation Loss', color='orange')\n",
    "    plt.xlabel('Batch Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Losses')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233f7834",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_SAMPLES = 32\n",
    "NB_subplots = 16\n",
    "nb_figures = NB_SAMPLES // NB_subplots\n",
    "\n",
    "for x, y in mnist_test:\n",
    "    # print(x.shape, y.shape)\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    break\n",
    "\n",
    "x_recon_cvae = cvae(x, y)[0]\n",
    "x_recon_inae = inae(x)\n",
    "x_recon_invae = invae(x)[0]\n",
    "\n",
    "for f in range(nb_figures):\n",
    "    fig, axs = plt.subplots(4, NB_subplots, figsize=(NB_subplots*2, 8), tight_layout=True)\n",
    "    for idx in range(min(NB_subplots, NB_SAMPLES - f * NB_subplots)):\n",
    "        axs[0, idx].imshow(x[f * NB_subplots + idx].cpu().reshape(28, 28), cmap=\"gray\")\n",
    "        axs[0, idx].set_title(f\"{y[f * NB_subplots + idx].argmax()}\", fontsize=20)\n",
    "        axs[0, idx].set_xticks([])\n",
    "        axs[0, idx].set_yticks([])\n",
    "\n",
    "        axs[1, idx].imshow(x_recon_cvae[f * NB_subplots + idx].detach().cpu().reshape(28, 28), cmap=\"gray\")\n",
    "        axs[1, idx].set_title(\" \")\n",
    "        axs[1, idx].set_xticks([])\n",
    "        axs[1, idx].set_yticks([])\n",
    "\n",
    "        axs[2, idx].imshow(x_recon_inae[f * NB_subplots + idx].detach().cpu().reshape(28, 28), cmap=\"gray\")\n",
    "        axs[2, idx].set_title(\" \")\n",
    "        axs[2, idx].set_xticks([])\n",
    "        axs[2, idx].set_yticks([])\n",
    "\n",
    "        axs[3, idx].imshow(x_recon_invae[f * NB_subplots + idx].detach().cpu().reshape(28, 28), cmap=\"gray\")\n",
    "        axs[3, idx].set_title(\" \")\n",
    "        axs[3, idx].set_xticks([])\n",
    "        axs[3, idx].set_yticks([])\n",
    "    axs[0, 0].set_ylabel(\"Original\", fontsize=15)\n",
    "    axs[1, 0].set_ylabel(\"CVAE Recon.\", fontsize=15)\n",
    "    axs[2, 0].set_ylabel(\"InvAE Recon.\", fontsize=15)\n",
    "    axs[3, 0].set_ylabel(\"InvVAE Recon.\", fontsize=15)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525e1e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT = 3\n",
    "x = []\n",
    "y = []\n",
    "for x_tmp, y_tmp in mnist_test:\n",
    "    x.append(x_tmp)\n",
    "    y.append(y_tmp)\n",
    "x = torch.cat(x).to(device)\n",
    "y = torch.cat(y).to(device)\n",
    "label = y.argmax(axis=1).detach().cpu()\n",
    "x_recon_inv_vae = invae(x)\n",
    "z = invae.encoder(x)\n",
    "z = z.detach().cpu()\n",
    "z_centers = []\n",
    "for i in range(10):\n",
    "    center = z[label == i].mean(axis=0)\n",
    "    z_centers.append(center)\n",
    "z_centers = torch.stack(z_centers)\n",
    "\n",
    "fig, axes = plt.subplots(Z2_DIM - 1, Z2_DIM - 1, figsize=(5 * (Z2_DIM - 1), 5 * (Z2_DIM - 1)), tight_layout=True)\n",
    "for i in range(Z2_DIM - 1):\n",
    "    for j in range(1, Z2_DIM):\n",
    "        if i < j:\n",
    "            im = axes[i, j-1].scatter(z_centers[:, i], z_centers[:, j],\n",
    "                                    c=range(10), cmap=\"tab10\", vmin=-.5, vmax=9.5)\n",
    "            axes[i, j-1].scatter(z[:, i], z[:, j],\n",
    "                            c=label, cmap=\"tab10\", alpha=0.1)\n",
    "            # axes[i, j-1].set_aspect('equal', adjustable='box')\n",
    "            # axes[i, j-1].set_xlim(-LIMIT, LIMIT)\n",
    "            # axes[i, j-1].set_ylim(-LIMIT, LIMIT)\n",
    "            for d in range(10):\n",
    "                axes[i, j-1].text(z_centers[d][i], z_centers[d][j], str(d), fontsize=15, ha='center', va='center')\n",
    "        else:\n",
    "            axes[i, j-1].axis('off')\n",
    "\n",
    "for i in range(Z2_DIM - 1):\n",
    "    for j in range(Z2_DIM - 1):\n",
    "        if i == j :\n",
    "            axes[i, j].set_ylabel(f\"$z_2$[{i}]\", fontsize=15)\n",
    "            axes[i, j].set_xlabel(f\"$z_2$[{j + 1}]\", fontsize=15)\n",
    "        elif i > j:\n",
    "            axes[i, j].axis('off')\n",
    "        # else:\n",
    "        #     axes[i, j].set_xticks([])\n",
    "        #     axes[i, j].set_yticks([])\n",
    "\n",
    "plt.suptitle(\"Latent Space of Invariant VAE\", fontsize=20)\n",
    "cbar = plt.colorbar(im, ax=axes, orientation='horizontal',\n",
    "                    fraction=0.02, pad=0.0)\n",
    "cbar.set_label('Digit Label', fontsize=15)\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "cbar.set_ticks(range(10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f55238",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROXY2INVAR_PATH = \"../checkpoints/mnist/digit/vaeproxy2invar.pth\"\n",
    "\n",
    "for param in invae.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "proxy2invar = ProxyRep2InvarRep(autoencoder=invae, reparameterize=True)\n",
    "proxy2invar = proxy2invar.to(device)\n",
    "\n",
    "if os.path.exists(PROXY2INVAR_PATH):\n",
    "    print(\"Loading pre-trained Proxy2Invar model...\")\n",
    "    proxy2invar.load_state_dict(torch.load(PROXY2INVAR_PATH, map_location=device))\n",
    "else:\n",
    "    print(\"No pre-trained model found. Starting from scratch.\")\n",
    "    optimizer = optim.Adam(proxy2invar.parameters(), lr=1e-3)\n",
    "    loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "    losses_train = []\n",
    "    losses_val = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "        proxy2invar.train()\n",
    "        for i, (x, y) in enumerate(tqdm(mnist_train)):\n",
    "            x = x.to(device)\n",
    "            \n",
    "            # Get real invariant representation from CVAE\n",
    "            with torch.no_grad():\n",
    "                z_invar = invae.cvae.encoder(x)\n",
    "                mu = z_invar[:, :invae.cvae.latent_dim]\n",
    "                logvar = z_invar[:, invae.cvae.latent_dim:]\n",
    "                z_invar = invae.cvae.reparameterize(mu, logvar)\n",
    "            \n",
    "            z_invar_pred = proxy2invar(x)\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(z_invar_pred, z_invar)\n",
    "            loss.backward()\n",
    "            losses_train.append(loss.item())\n",
    "            optimizer.step()\n",
    "\n",
    "        proxy2invar.eval()\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for x, y in mnist_val:\n",
    "                x = x.to(device)\n",
    "                z_invar = inae.cvae.encoder(x)\n",
    "                mu = z_invar[:, :inae.cvae.latent_dim]\n",
    "                logvar = z_invar[:, inae.cvae.latent_dim:]\n",
    "                z_invar = inae.cvae.reparameterize(mu, logvar)\n",
    "\n",
    "                z_invar_pred = proxy2invar(x)\n",
    "                val_loss = loss_fn(z_invar_pred, z_invar)\n",
    "                total_val_loss += val_loss.item()\n",
    "            avg_val_loss = total_val_loss / len(mnist_val)\n",
    "            losses_val.append(avg_val_loss)\n",
    "            print(f\"\\nEpoch {epoch + 1} Validation Loss: {avg_val_loss:.4f}\")\n",
    "    torch.save(proxy2invar.state_dict(), PROXY2INVAR_PATH)\n",
    "\n",
    "    nb_minibatches = len(mnist_train)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses_train, label='Training Loss', color='blue')\n",
    "    plt.plot(range(nb_minibatches, nb_minibatches * EPOCHS + 1, nb_minibatches),\n",
    "                losses_val, label='Validation Loss', color='orange')\n",
    "    plt.xlabel('Batch Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('VAE Proxy to Invariant Representation MSE')\n",
    "    plt.legend()\n",
    "    plt.xscale('log')\n",
    "    plt.ylim(0.94, 1.1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed19d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROXY2LAB_PATH = \"../checkpoints/mnist/digit/vaeproxy2lab.pth\"\n",
    "\n",
    "proxy2lab = ProxyRep2Label(autoencoder=invae, reparameterize=True, nb_labels=10)\n",
    "proxy2lab = proxy2lab.to(device)\n",
    "\n",
    "if os.path.exists(PROXY2LAB_PATH):\n",
    "    print(\"Loading pre-trained Proxy2Label model...\")\n",
    "    proxy2lab.load_state_dict(torch.load(PROXY2LAB_PATH, map_location=device))\n",
    "else:\n",
    "    print(\"No pre-trained model found. Starting from scratch.\")\n",
    "    optimizer = optim.Adam(proxy2lab.parameters(), lr=1e-3)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "    losses_train = []\n",
    "    losses_val = []\n",
    "    accuracies_val = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "        proxy2lab.train()\n",
    "        for i, (x, y) in enumerate(tqdm(mnist_train)):\n",
    "            x = x.to(device)\n",
    "            y = y.float().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = proxy2lab(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            loss.backward()\n",
    "            losses_train.append(loss.item())\n",
    "            optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            proxy2lab.eval()\n",
    "            total_val_loss = 0\n",
    "            total_val_accu = 0\n",
    "\n",
    "            for x, y in mnist_val:\n",
    "                x = x.to(device)\n",
    "                y = y.float().to(device)\n",
    "                y_pred = proxy2lab(x)\n",
    "                val_loss = loss_fn(y_pred, y)\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "                lab_pred = y_pred.argmax(axis=1)\n",
    "                lab_true = y.argmax(axis=1)\n",
    "                acc = (lab_pred == lab_true).float().mean().item()\n",
    "                total_val_accu += acc\n",
    "\n",
    "            avg_val_loss = total_val_loss / len(mnist_val)\n",
    "            avg_val_accu = total_val_accu / len(mnist_val)\n",
    "            accuracies_val.append(avg_val_accu)\n",
    "            print(f\"\\nEpoch {epoch + 1} Validation Loss: {avg_val_loss:.4f}, Accuracy: {avg_val_accu:.4f}\")\n",
    "            losses_val.append(avg_val_loss)\n",
    "            # print(f\"\\nEpoch {epoch + 1} Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "    torch.save(proxy2lab.state_dict(), PROXY2LAB_PATH)\n",
    "\n",
    "    nb_minibatches = len(mnist_train)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n",
    "    axes[0].plot(losses_train, label='Training Loss', color='blue')\n",
    "    axes[0].plot(range(nb_minibatches, nb_minibatches * EPOCHS + 1, nb_minibatches),\n",
    "                losses_val, label='Validation Loss', color='orange')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('VAE Proxy to Label Cross Entropy')\n",
    "    axes[0].legend()\n",
    "    axes[0].set_xscale('log')\n",
    "    axes[0].set_xticks([])\n",
    "    xlim = axes[0].get_xlim()\n",
    "\n",
    "    axes[1].plot(range(nb_minibatches, nb_minibatches * EPOCHS + 1, nb_minibatches),\n",
    "                accuracies_val, label='Validation Accuracy', color='green')\n",
    "    axes[1].set_xlabel('Batch Iterations')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('VAE Proxy to Label Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].set_xscale('log')\n",
    "    axes[1].set_xlim(xlim)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f6a0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy2lab.eval()\n",
    "\n",
    "lab_true_all = []\n",
    "lab_pred_all = []\n",
    "\n",
    "for x, y in mnist_test:\n",
    "    x = x.to(device)\n",
    "    y = y.float().to(device)\n",
    "    lab_true = y.argmax(axis=1)\n",
    "    lab_true_all.append(lab_true)\n",
    "\n",
    "    y_pred = proxy2lab(x)\n",
    "    lab_pred = y_pred.argmax(axis=1)\n",
    "    lab_pred_all.append(lab_pred)\n",
    "lab_true_all = torch.cat(lab_true_all).detach().cpu()\n",
    "lab_pred_all = torch.cat(lab_pred_all).detach().cpu()\n",
    "confusion_matrix = torch.zeros(10, 10, dtype=torch.int64)\n",
    "for true, pred in zip(lab_true_all, lab_pred_all):\n",
    "    confusion_matrix[true, pred] += 1\n",
    "accuracy = (lab_true_all == lab_pred_all).float().mean().item()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(confusion_matrix, cmap='Blues', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title(f\"Confusion Matrix of VAE Proxy to Label (acc.: {accuracy:.3f})\")\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.xticks(ticks=range(10), labels=range(10))\n",
    "plt.yticks(ticks=range(10), labels=range(10))\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "invrep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
